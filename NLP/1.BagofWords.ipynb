{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'love', 'sky', ',', 'I', 'love', 'sea', '.'], ['I', 'like', 'running', ',', 'I', 'love', 'reading', '.']]\n"
     ]
    }
   ],
   "source": [
    "# exp.1\n",
    "sent1=\"I love sky, I love sea.\"\n",
    "sent2=\"I like running, I love reading.\"\n",
    "# step.1 分词\n",
    "sents=[sent1,sent2]\n",
    "texts=[[word for word in word_tokenize(sent)]for sent in sents]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reading', 'like', ',', 'sky', 'running', 'sea', 'I', 'love', '.'}\n"
     ]
    }
   ],
   "source": [
    "# step.2 构建语料库\n",
    "all_list=[]\n",
    "for text in texts:\n",
    "    all_list+=text\n",
    "corpus=set(all_list)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reading': 0, 'like': 1, ',': 2, 'sky': 3, 'running': 4, 'sea': 5, 'I': 6, 'love': 7, '.': 8}\n"
     ]
    }
   ],
   "source": [
    "# step.3 对语料库中的单词及标点建立数字映射，便于后续的句子的向量表示。\n",
    "corpus_dict=dict(zip(corpus,range(len(corpus))))\n",
    "print(corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 0), (2, 1), (3, 1), (4, 0), (5, 1), (6, 2), (7, 2), (8, 1)]\n",
      "[(0, 1), (1, 1), (2, 1), (3, 0), (4, 1), (5, 0), (6, 2), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "# step.4 建立句子的向量表示\n",
    "# 这个表示向量并不是简单地以单词或标点出现与否来选择0，1数字，\n",
    "# 而是把单词或标点的出现频数作为其对应的数字表示\n",
    "def vector_rep(text, corpus_dict):\n",
    "    vec=[]\n",
    "    for key in corpus_dict.keys():\n",
    "        if key in text:\n",
    "            vec.append((corpus_dict[key],text.count(key)))\n",
    "        else:\n",
    "            vec.append((corpus_dict[key],0))\n",
    "    vec=sorted(vec,key=lambda x:x[0])\n",
    "    return vec\n",
    "\n",
    "vec1=vector_rep(sents[0],corpus_dict)\n",
    "vec2=vector_rep(sents[1],corpus_dict)\n",
    "print(vec1)\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7302967433402214\n"
     ]
    }
   ],
   "source": [
    "# 以上即为词袋模型\n",
    "# 计算句子向量间的相似度\n",
    "#     一般会选择余弦相似度\n",
    "from math import sqrt\n",
    "# 计算余弦相似度\n",
    "def similarity_with_2_sents(vec1,vec2):\n",
    "    inner_product=0\n",
    "    square_vec1=0\n",
    "    square_vec2=0\n",
    "    for tup1,tup2 in zip(vec1,vec2):\n",
    "        inner_product += tup1[1]*tup2[1]\n",
    "        square_vec1+=tup1[1]**2\n",
    "        square_vec2+=tup2[1]**2\n",
    "    return (inner_product/sqrt(square_vec1*square_vec2))\n",
    "\n",
    "cosin_sim=similarity_with_2_sents(vec1,vec2)\n",
    "print(cosin_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 2 documents in 0 shards (stored under -Similarity-index)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "调包实现上述功能\n",
    "\"\"\"\n",
    "# 调用gensim模块\n",
    "from gensim import corpora\n",
    "from gensim.similarities import Similarity\n",
    "\n",
    "# 语料库\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# 利用doc2bow作为词袋模型\n",
    "corpus=[dictionary.doc2bow(text) for text in texts]\n",
    "similarity = Similarity('-Similarity-index',corpus,num_features=len(dictionary))\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "利用gensim计算得到两个句子的相似度： 0.7303。\n"
     ]
    }
   ],
   "source": [
    "# 获取句子相似度\n",
    "new_sensence = sent1\n",
    "test_corpus_1 = dictionary.doc2bow(word_tokenize(new_sensence))\n",
    "cosin_sim=similarity[test_corpus_1][1]\n",
    "print(\"利用gensim计算得到两个句子的相似度： %.4f。\"%cosin_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
